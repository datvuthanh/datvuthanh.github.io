# Paper Notes
This repository contains my paper reading notes on deep learning and machine learning. It is inspired by [Denny Britz](https://github.com/dennybritz/deeplearning-papernotes), [Daniel Takeshi](https://github.com/DanielTakeshi/Paper_Notes) and especially [Patrick Langechuan Liu](https://www.linkedin.com/in/patrick-llgc/).

## About Me
My name is [Dat Vu](https://www.linkedin.com/in/datvuthanh), and I am currently leading the AI Team at [PhenikaaX](https://phenikaa-x.com), a rapidly growing autonomous and industrial robot company where I serve as the Computer Vision Leader. I have a passion for seeking answers to complex questions and take great joy in exploring and deeply understanding mathematical concepts. You can see my publications [here](https://scholar.google.com/citations?user=F2RswlkAAAAJ&hl=vi&oi=ao).

## My ML/DL Notes

You can read my notes [here](notes/start.md).

## 2023-08

- [PaLM-E: An Embodied Multimodal Language Model](https://palm-e.github.io/assets/palm-e.pdf) [Danny Driess]
- [Vision-Language Models for Vision Tasks: A Survey](https://arxiv.org/pdf/2304.00685.pdf) [Jingyi Zhang]
- [RT-2: Vision-Language-Action Models Transfer Web Knowledge to Robotic Control](https://robotics-transformer2.github.io/assets/rt2.pdf) [Anthony Brohan]
- [RT-1: Robotics Transformer for Real-World Control at Scale](https://arxiv.org/abs/2212.06817) [Anthony Brohan]
## 2023-07

- [VN-Transformer: Rotation-Equivariant Attention for Vector
Neurons](https://arxiv.org/pdf/2206.04176.pdf) [Serge Assaad]
- [LightGlue: Local Feature Matching at Light Speed](https://arxiv.org/abs/2306.13643) [Philipp Lindenberger]
- [Trajectory-guided Control Prediction for End-to-end Autonomous Driving: A Simple yet Strong Baseline](https://arxiv.org/pdf/2206.08129.pdf) <kbd>NeurIPS 2022</kbd> [Penghao Wu]
- [OpenLane-V2: A Topology Reasoning Benchmark for Scene Understanding in Autonomous Driving](https://arxiv.org/abs/2304.10440) [Huijie Wang]
- [MINEDOJO: Building Open-Ended Embodied Agents with Internet-Scale Knowledge](https://proceedings.neurips.cc/paper_files/paper/2022/file/74a67268c5cc5910f64938cac4526a90-Paper-Datasets_and_Benchmarks.pdf) <kbd>NeurIPS 2022</kbd> [Linxi Fan]
- [Riemannian Score-Based Generative Modelling](https://proceedings.neurips.cc/paper_files/paper/2022/file/105112d52254f86d5854f3da734a52b4-Paper-Conference.pdf) <kbd>NeurIPS 2022</kbd> [Valentin De Bortoli]
- [Gradient Descent: The Ultimate Optimizer](https://proceedings.neurips.cc/paper_files/paper/2022/file/36ce475705c1dc6c50a5956cedff3d01-Paper-Conference.pdf) <kbd>NeurIPS 2022</kbd> [Kartik Chandra]
- [Llama 2: Open Foundation and Fine-Tuned Chat Models](https://scontent-hkg4-1.xx.fbcdn.net/v/t39.2365-6/10000000_663429262362723_1696968207443577320_n.pdf?_nc_cat=101&ccb=1-7&_nc_sid=3c67a6&_nc_ohc=5ol-jUSglG4AX9l70Cd&_nc_ht=scontent-hkg4-1.xx&oh=00_AfBZLk5cJwQAsa7G6JIbzCTUZhJpUzNyfgAPpg391bbdrA&oe=64BBB691) [Hugo Touvron]
- [Dilated Neighborhood Attention Transformer](https://arxiv.org/abs/2209.15001) [Ali Hassani]
- [Neighborhood Attention Transformer](https://arxiv.org/abs/2204.07143) <kbd>CVPR 2023</kbd> [Ali Hassani]
- [PlanT: Explainable Planning Transformers via Object-Level Representations](https://arxiv.org/abs/2210.14222) <kbd>CoRL 2022</kbd> [Katrin Renz]
- [Think Twice before Driving: Towards Scalable Decoders for End-to-End Autonomous Driving](https://arxiv.org/abs/2305.06242) <kbd>CVPR 2023</kbd> [Xiaosong Jia]
- [Scaling Self-Supervised End-to-End Driving with Multi-View Attention Learning](https://arxiv.org/abs/2302.03198) [Yi Xiao]
- [Gato: A Generalist Agent](https://arxiv.org/abs/2205.06175) <kbd>TMLR 2022 </kbd> [Scott Reed]
- [Bytes Are All You Need: Transformers Operating Directly On File Bytes](https://arxiv.org/abs/2306.00238) [Maxwell Horton]

## 2023-06

- [Vision Transformer with Deformable Attention](https://arxiv.org/abs/2201.00520) [Zhuofan Xia]
- [Planning-oriented Autonomous Driving](https://arxiv.org/abs/2212.10156) <kbd>CVPR 2023 Best Paper</kbd> [Yihan Hu]
- [MetaFormer Is Actually What You Need for Vision](https://arxiv.org/abs/2111.11418) [Weihao Yu]
- [A Unified Sequence Interface for Vision Tasks](https://arxiv.org/pdf/2206.07669.pdf) [Ting Chen]
- [Pix2seq: A Language Modeling Framework for Object Detection](https://arxiv.org/abs/2109.10852) [Ting Chen]
- [FlashAttention: Fast and Memory-Efficient Exact Attention with IO-Awareness](https://arxiv.org/pdf/2205.14135.pdf) [Tri Dao]
- [Better plain ViT baselines for ImageNet-1k](https://arxiv.org/pdf/2205.01580.pdf) [Lucas Beyer]
- [FUTR3D: A Unified Sensor Fusion Framework for 3D Detection](https://arxiv.org/pdf/2203.10642.pdf) [Xuanyao Chen]
- [Iterative Deep Homography Estimation](https://arxiv.org/pdf/2203.15982.pdf) <kbd>CVPR 2022</kbd> [Si-Yuan Cao]
- [Recurrent Homography Estimation Using Homography-Guided Image Warping and Focus Transformer](https://openaccess.thecvf.com/content/CVPR2023/papers/Cao_Recurrent_Homography_Estimation_Using_Homography-Guided_Image_Warping_and_Focus_Transformer_CVPR_2023_paper.pdf) <kbd>CVPR 2023</kbd> [Si-Yuan Cao]
- [QLORA: Efficient Finetuning of Quantized LLMs](https://arxiv.org/pdf/2305.14314v1.pdf) [Tim Dettmers]
- [LORA: LOW-RANK ADAPTATION OF LARGE LAN- GUAGE MODELS](https://arxiv.org/pdf/2106.09685.pdf) [[Notes](notes/lora.md)] [Edward Hu]
- [Occupancy Networks: Learning 3D Reconstruction in Function Space](https://arxiv.org/abs/1812.03828) <kbd>CVPR 2019</kbd> [Andreas Geiger]
- [Occ3D: A Large-Scale 3D Occupancy Prediction Benchmark for Autonomous Driving](https://arxiv.org/abs/2304.14365) [Occupancy Network, Zhao Hang]

## 2023-05

- [SurroundOcc: Multi-Camera 3D Occupancy Prediction for Autonomous Driving](https://arxiv.org/abs/2303.09551) [Occupancy Network, Wei Yi, Jiwen Lu]
- [LocalTrans: A Multiscale Local Transformer Network for Cross-Resolution Homography Estimation](https://arxiv.org/abs/2106.04067) [Homography Estimation]
- [Transformer Feed-Forward Layers Are Key-Value Memories](https://arxiv.org/abs/2012.14913) <kbd>EMNLP 2021</kbd>
- [OccFormer: Dual-path Transformer for Vision-based 3D Semantic Occupancy Prediction](https://arxiv.org/abs/2304.05316) [Occupancy Network, PhiGent]

## 2023-04

- [ViP3D: End-to-end Visual Trajectory Prediction via 3D Agent Queries](https://arxiv.org/abs/2208.01582)
- [SAM: Segment Anything](https://arxiv.org/abs/2304.02643) [FAIR]
- [BEV-LaneDet: a Simple and Effective 3D Lane Detection Baseline](https://arxiv.org/abs/2210.06006) <kbd>CVPR 2023</kbd> [BEVNet]
- [BEVSegFormer: Bird's Eye View Semantic Segmentation From Arbitrary Camera Rigs](https://arxiv.org/abs/2203.04050) [BEVNet]

## 2023-03

- [VAD: Vectorized Scene Representation for Efficient Autonomous Driving](https://arxiv.org/abs/2303.12077) [Horizon]
- [BEVPoolv2: A Cutting-edge Implementation of BEVDet Toward Deployment](https://arxiv.org/abs/2211.17111) [BEVDet, PhiGent]
- [Differentiable Raycasting for Self-supervised Occupancy Forecasting](https://www.ecva.net/papers/eccv_2022/papers_ECCV/html/1105_ECCV_2022_paper.php)
- [End-to-end Interpretable Neural Motion Planner](https://arxiv.org/abs/2101.06679)
- [Safe Local Motion Planning with Self-Supervised Freespace Forecasting](https://openaccess.thecvf.com/content/CVPR2021/papers/Hu_Safe_Local_Motion_Planning_With_Self-Supervised_Freespace_Forecasting_CVPR_2021_paper.pdf)
- [DETR3D: 3D Object Detection from Multi-view Images via 3D-to-2D Queries](https://arxiv.org/abs/2110.06922) <kbd>CoRL 2021</kbd> [BEVNet, transformers]

## 2023-02

- [TPVFormer: Tri-Perspective View for Vision-Based 3D Semantic Occupancy Prediction](https://arxiv.org/abs/2302.07817) <kbd>CVPR 2023</kbd> [Occupancy Network, Jiwen Lu]
- [ST-P3: End-to-end Vision-based Autonomous Driving via Spatial-Temporal Feature Learning](https://arxiv.org/abs/2207.07601) <kbd>ECCV 2022</kbd> [Hongyang Li]
- [BEVFormer: Learning Bird's-Eye-View Representation from Multi-Camera Images via Spatiotemporal Transformers](https://arxiv.org/abs/2203.17270)  <kbd>ECCV 2022</kbd> [BEVNet, Hongyang Li, Jifeng Dai]
- [BEVDet4D: Exploit Temporal Cues in Multi-camera 3D Object Detection](https://arxiv.org/abs/2203.17054) [BEVNet]
- [BEVerse: Unified Perception and Prediction in Birds-Eye-View for Vision-Centric Autonomous Driving](https://arxiv.org/abs/2205.09743) [Jiwen Lu, BEVNet, perception + prediction]
- [BEVFusion: Multi-Task Multi-Sensor Fusion with Unified Bird's-Eye View Representation](https://arxiv.org/abs/2205.13542) [BEVNet, Han Song]
- [PersFormer: 3D Lane Detection via Perspective Transformer and the OpenLane Benchmark](https://arxiv.org/abs/2203.11089) [BEVNet, lane line]
- [VectorMapNet: End-to-end Vectorized HD Map Learning](https://arxiv.org/abs/2206.08920) [BEVNet, LLD, Hang Zhao]
- [PETR: Position Embedding Transformation for Multi-View 3D Object Detection](https://arxiv.org/abs/2203.05625) <kbd>ECCV 2022</kbd> [BEVNet]
- [PETRv2: A Unified Framework for 3D Perception from Multi-Camera Images](https://arxiv.org/abs/2206.01256) [BEVNet, MegVii]
- [M^2BEV: Multi-Camera Joint 3D Detection and Segmentation with Unified Birds-Eye View Representation](https://arxiv.org/abs/2204.05088) [BEVNet, nvidia]
- [BEVDepth: Acquisition of Reliable Depth for Multi-view 3D Object Detection](https://arxiv.org/abs/2206.10092) [BEVNet, NuScenes SOTA, Megvii]
- [CVT: Cross-view Transformers for real-time Map-view Semantic Segmentation](https://arxiv.org/abs/2205.02833) <kbd>CVPR 2022 oral</kbd> [UTAustin, Philipp]
- [Wayformer: Motion Forecasting via Simple & Efficient Attention Networks](https://arxiv.org/abs/2207.05844) [Behavior prediction, Waymo]
- [HDMapNet: An Online HD Map Construction and Evaluation Framework](https://arxiv.org/abs/2107.06307) <kbd>CVPR 2021 workshop</kbd> [youtube video only, Li Auto]
- [FIERY: Future Instance Prediction in Bird's-Eye View from Surround Monocular Cameras](https://arxiv.org/abs/2104.10490) <kbd>ICCV 2021</kbd> [BEVNet, perception + prediction]
